{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Linear Regression</h3>\n",
    "<h4>Packages Used</h4>\n",
    "<ul>\n",
    "    <li>numpy</li>\n",
    "    <li>matplotlib</li>\n",
    "</ul>\n",
    "<h3>Import necessary packages</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ReadData(data,separator): Helper function to read data</h3>\n",
    "<h4> Assumes data is of the form X[0], X[1], ..., X[n], Y</h4>\n",
    "<h5>Where X[i] is a feature and Y is the label</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadData(data,separator):\n",
    "    \n",
    "    XY =  np.genfromtxt(data, delimiter=separator)\n",
    "    m=XY.shape[0]\n",
    "    Y=XY[:,-1].reshape(m,1)\n",
    "    X=XY[:,0:-1]\n",
    "    bias = np.zeros((X.shape[1],1))\n",
    "    theta = np.zeros((X.shape[1],1))\n",
    "    return X,Y,m,bias,theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Normalize(data): Helper function to Normalize data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(data):\n",
    "    \n",
    "    Mu = np.mean(X, axis=0)\n",
    "    Sigma = np.std(X, axis=0)\n",
    "    data=((data-Mu)/Sigma)\n",
    "    return data,Mu,Sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>GradDescent_CostCalc(iter1,X,theta,bias,Y,learningratebym,costweight): Function to calculate costs, final theata, biases using Gradient Descent</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradDescent_CostCalc(iter1,X,theta,bias,Y,learningratebym,costweight):\n",
    "    costs=[]\n",
    "    for i in range(iter1):\n",
    "        H = np.dot(X,theta) + bias\n",
    "        diff = H - Y\n",
    "        delta = learningratebym * np.dot(diff.T,X).T\n",
    "        theta = theta - delta\n",
    "        bias = bias - (learningratebym * sum(diff))\n",
    "        J = costweight * sum(np.square(diff))\n",
    "        costs.append(J.item(0))\n",
    "    return costs,bias,theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>CostCalc(X,theta,bias,Y,costweight): Function to calculate cost</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CostCalc(X,theta,bias,Y,costweight):\n",
    "\n",
    "    H = np.dot(X,theta) + bias\n",
    "    diff = H - Y\n",
    "    J = costweight * sum(np.square(diff))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>PlotData(Original_X,Normalized_X,Y,trainedtheta,trainedbias,costs,fignumber=1): Helper function to Plot data,predicted target and costs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotData(Original_X,Normalized_X,Y,trainedtheta,trainedbias,costs,fignumber=1):\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(fignumber)\n",
    "    plt.subplot(211)\n",
    "    plt.plot(Original_X,Y,'r+')\n",
    "    plt.ylabel('Label')\n",
    "    plt.xlabel('Feature')\n",
    "    plt.plot(Original_X, (np.dot(Normalized_X,trainedtheta) + trainedbias), 'b-')\n",
    "    plt.subplot(212)\n",
    "    plt.ylabel('Cost')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.plot(range(iter1),costs, '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ContourPlot(X,Y,costweight,plotspace_x = -10,plotspace_y = 20) Helper function to make the contour, surface plots</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ContourPlot(X,Y,costweight,plotspace_x = -10,plotspace_y = 20):\n",
    "    bias_vals = np.linspace(plotspace_x, plotspace_y, 100)\n",
    "    theta_vals = np.linspace(plotspace_x, plotspace_y, 100)\n",
    "    costs=np.zeros((len(bias_vals),len(theta_vals)))\n",
    "    for i in range(len(bias_vals)):\n",
    "        for j in range(len(theta_vals)):\n",
    "            ##costs[j][i] because contour plot needs costs[i][j] Transpose\n",
    "            costs[j][i] = CostCalc(X,theta_vals[j],bias_vals[i],Y,costweight)\n",
    "    X , Y = np.meshgrid(bias_vals, theta_vals)\n",
    "    plt.figure(2)\n",
    "    CS = plt.contour(X, Y, costs, np.logspace(-2, 3, 20))\n",
    "    plt.clabel(CS, inline=1, fontsize=10)\n",
    "    plt.title('Costs Contour Plot')\n",
    "    plt.ylabel(r'$\\theta_1$')\n",
    "    plt.xlabel(r'$\\theta_0$')\n",
    "    fig = plt.figure(3)\n",
    "    ax = fig.gca(projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, costs,rstride=1, cstride=1, cmap='PuBu_r', linewidth=0, antialiased=False)\n",
    "    ax.set_xlabel(r'$\\theta_0$')\n",
    "    ax.set_ylabel(r'$\\theta_1$')\n",
    "    ax.set_zlabel('Costs Surface Plot')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Main Code below</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y,m,bias,theta = ReadData('1DDS.txt',',')\n",
    "Original_X = X\n",
    "X,Mu,Sigma = Normalize(X)\n",
    "learningrate = 0.01\n",
    "iter1 = 1500\n",
    "learningratebym= learningrate/m\n",
    "costweight = 1/(2*m)\n",
    "costs,trainedbias,trainedtheta = GradDescent_CostCalc(iter1,X,theta,bias,Y,\n",
    "                                                      learningratebym,costweight)\n",
    "PlotData(Original_X,X,Y,trainedtheta,trainedbias,costs)\n",
    "ContourPlot(X,Y,costweight,plotspace_x = -10,plotspace_y = 20)\n",
    "actual_input = np.array([7.5]).reshape(1,1)\n",
    "normalized_input=(actual_input-Mu)/Sigma\n",
    "print('For population = {}, we predict a profit of {}'.format(\n",
    "             actual_input.item(0) * 10000,(trainedbias + np.dot(normalized_input,trainedtheta)).item(0) * 10000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
