{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Dense, Dropout, Flatten, AlphaDropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import backend as K \n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.preprocessing import Normalizer, QuantileTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from time import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Labels to Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(optimizer=Adam(amsgrad=True),\n",
    "                input_shape=input_shape,\n",
    "                num_classes=num_classes,\n",
    "                activation1='elu',\n",
    "                activation2='elu',\n",
    "                activation3='elu',\n",
    "                activation4='elu',\n",
    "                units1=1,\n",
    "                units2=1,\n",
    "                units3=1,\n",
    "                units4=1,\n",
    "                dropout1=0.3,\n",
    "                dropout2=0.3,\n",
    "                dropout3=0.3,\n",
    "                dropout4=0.3,\n",
    "                k1=8,\n",
    "                k2=7,\n",
    "                p1=2,\n",
    "                p2=2,\n",
    "                op_activation='softmax',\n",
    "                loadprevmodel=False,\n",
    "                modelname='Keras-MNIST'\n",
    "               ):\n",
    "    if loadprevmodel:\n",
    "        try:\n",
    "            model = load_model(modelname + '.h5')\n",
    "            print('Model loaded successfully')\n",
    "        except IOError:\n",
    "            print('Loading previous model failed, Building a new model')       \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(units1, kernel_size=(k1, k1),\n",
    "                     activation=activation1,\n",
    "                     input_shape=input_shape,\n",
    "                     padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(p1, p1), strides=2, padding='same'))\n",
    "    if activation1 == 'selu':\n",
    "        model.add(AlphaDropout(dropout1))\n",
    "    else:\n",
    "        model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(units2, (k2, k2), activation=activation2, padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(p2, p2), strides=2, padding='same'))\n",
    "    if activation2 == 'selu':\n",
    "        model.add(AlphaDropout(dropout2))\n",
    "    else:\n",
    "        model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units3, activation=activation3))\n",
    "    if activation3 == 'selu':\n",
    "        model.add(AlphaDropout(dropout3))\n",
    "    else:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(units4, activation=activation4))\n",
    "    if activation4 == 'selu':\n",
    "        model.add(AlphaDropout(dropout4))\n",
    "    else:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation=op_activation))\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = True\n",
    "modelh5 = 'Keras-MNIST'\n",
    "batch_size = 256\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 62s 2ms/step - loss: 2.3064 - acc: 0.1366\n",
      "30000/30000 [==============================] - 20s 651us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 56s 2ms/step - loss: 2.3095 - acc: 0.1171\n",
      "30000/30000 [==============================] - 20s 660us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 52s 2ms/step - loss: 0.2800 - acc: 0.9136\n",
      "30000/30000 [==============================] - 15s 485us/step\n",
      "Epoch 1/1\n",
      "30000/30000 [==============================] - 49s 2ms/step - loss: 0.2499 - acc: 0.9228\n",
      "30000/30000 [==============================] - 15s 492us/step\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 97s 2ms/step - loss: 0.1676 - acc: 0.9481\n",
      "BayesSearchCV took 416.96 seconds for 32 candidates parameter settings.\n",
      "val. score: 0.9612666666666667\n",
      "60000/60000 [==============================] - 30s 494us/step\n",
      "test score: 0.9836\n",
      "{'activation1': 'selu', 'activation2': 'relu', 'activation3': 'selu', 'activation4': 'relu', 'dropout1': 0.03054859373253639, 'dropout2': 0.01821491262823199, 'dropout3': 0.22391179253754676, 'dropout4': 0.04238128630404382, 'k1': 28, 'k2': 14, 'p1': 4, 'p2': 3, 'units1': 23, 'units2': 116, 'units3': 972, 'units4': 62}\n"
     ]
    }
   ],
   "source": [
    "params_dict ={'dropout1': Real(0.01, 1.0, 'log-uniform'),\n",
    "              'dropout2': Real(0.01, 1.0, 'log-uniform'),\n",
    "              'dropout3': Real(0.01, 1.0, 'log-uniform'),\n",
    "              'dropout4': Real(0.01, 1.0, 'log-uniform'),\n",
    "              'units1': Integer(16,128),\n",
    "              'units2': Integer(16,128),\n",
    "              'units3': Integer(128,1024),\n",
    "              'units4': Integer(32,64),\n",
    "              'activation1': Categorical(['elu', 'relu', 'selu']),\n",
    "              'activation2': Categorical(['elu', 'relu', 'selu']),\n",
    "              'activation3': Categorical(['elu', 'relu', 'selu']),\n",
    "              'activation4': Categorical(['elu', 'relu', 'selu']),\n",
    "              'k1': Integer(3,img_rows),\n",
    "              'k2': Integer(3,img_rows),\n",
    "              'p1': Integer(2,8),\n",
    "              'p2': Integer(2,8),\n",
    "        }\n",
    "if search:\n",
    "    random_search = BayesSearchCV(estimator=KerasClassifier(build_model,\n",
    "                                                            input_shape=input_shape,\n",
    "                                                            num_classes=num_classes,\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            epochs=epochs,\n",
    "                                                            verbose=1\n",
    "                                                           ),\n",
    "                                  search_spaces=params_dict,\n",
    "                                  scoring='accuracy',\n",
    "                                  n_iter=2,\n",
    "                                  cv=2,\n",
    "                                  verbose=0\n",
    "                                 )\n",
    "\n",
    "    start = time()\n",
    "    random_search.fit(x_train, y_train)\n",
    "    print(\"BayesSearchCV took %.2f seconds for %d candidates\"\n",
    "          \" parameter settings.\" % ((time() - start), random_search.total_iterations))\n",
    "\n",
    "    print(\"val. score: %s\" % random_search.best_score_)\n",
    "    print(\"test score: %s\" % random_search.score(x_train, y_train))\n",
    "    print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9612666666666667\n",
      "{'activation1': 'selu', 'activation2': 'relu', 'activation3': 'selu', 'activation4': 'relu', 'dropout1': 0.03054859373253639, 'dropout2': 0.01821491262823199, 'dropout3': 0.22391179253754676, 'dropout4': 0.04238128630404382, 'k1': 28, 'k2': 14, 'p1': 4, 'p2': 3, 'units1': 23, 'units2': 116, 'units3': 972, 'units4': 62}\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_score_)\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Docs\n",
    "#### http://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py\n",
    "### Bayes Search CV docs\n",
    "#### https://github.com/scikit-optimize/scikit-optimize/blob/master/skopt/searchcv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.1626 - acc: 0.9492\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 90s 2ms/step - loss: 0.0500 - acc: 0.9841\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 91s 2ms/step - loss: 0.0336 - acc: 0.9896\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 90s 2ms/step - loss: 0.0251 - acc: 0.9919\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 90s 2ms/step - loss: 0.0185 - acc: 0.9943\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 90s 1ms/step - loss: 0.0158 - acc: 0.9949\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 90s 1ms/step - loss: 0.0113 - acc: 0.9965\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 91s 2ms/step - loss: 0.0099 - acc: 0.9968\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 90s 1ms/step - loss: 0.0082 - acc: 0.9974\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 90s 2ms/step - loss: 0.0055 - acc: 0.9985\n",
      "60000/60000 [==============================] - 30s 497us/step\n"
     ]
    }
   ],
   "source": [
    "params = {'activation1': 'selu', 'activation2': 'relu', 'activation3': 'selu', 'activation4': 'relu', 'dropout1': 0.03054859373253639, 'dropout2': 0.01821491262823199, 'dropout3': 0.22391179253754676, 'dropout4': 0.04238128630404382, 'k1': 28, 'k2': 14, 'p1': 4, 'p2': 3, 'units1': 23, 'units2': 116, 'units3': 972, 'units4': 62}\n",
    "clf = KerasClassifier(build_model,\n",
    "                      input_shape=input_shape,\n",
    "                      num_classes=num_classes,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=10,\n",
    "                      verbose=1,\n",
    "                     **params)\n",
    "clf.fit(x_train, y_train)\n",
    "y_true, y_pred = y_train, clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      5923\n",
      "          1       1.00      1.00      1.00      6742\n",
      "          2       1.00      1.00      1.00      5958\n",
      "          3       1.00      1.00      1.00      6131\n",
      "          4       1.00      1.00      1.00      5842\n",
      "          5       1.00      1.00      1.00      5421\n",
      "          6       1.00      1.00      1.00      5918\n",
      "          7       1.00      1.00      1.00      6265\n",
      "          8       1.00      1.00      1.00      5851\n",
      "          9       1.00      1.00      1.00      5949\n",
      "\n",
      "avg / total       1.00      1.00      1.00     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 586us/step\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.96      0.97       980\n",
      "          1       1.00      0.97      0.98      1135\n",
      "          2       0.65      1.00      0.79      1032\n",
      "          3       0.93      0.85      0.89      1010\n",
      "          4       0.98      0.90      0.94       982\n",
      "          5       0.96      0.90      0.93       892\n",
      "          6       0.97      0.94      0.95       958\n",
      "          7       0.99      0.82      0.90      1028\n",
      "          8       0.98      0.77      0.86       974\n",
      "          9       0.83      0.95      0.88      1009\n",
      "\n",
      "avg / total       0.93      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = y_test, clf.predict(x_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
